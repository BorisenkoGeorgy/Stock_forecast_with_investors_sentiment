{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c433ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from configparser import ConfigParser\n",
    "import datetime\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from models.code import CRNN, CNN, CBiRNN, CTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08e68c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigParser()\n",
    "config.read(['configs/main.ini', 'configs/main_secret.ini'], encoding='utf-8')\n",
    "\n",
    "cfg = {\n",
    "    'debug': True,\n",
    "    'seed': 123,\n",
    "    'device': 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    'n_devices': torch.cuda.device_count() if torch.cuda.is_available() else 1,\n",
    "    'companies': ['CHMF', 'GAZP', 'GMKN', 'LKOH', 'MOEX', 'NLMK', 'NVTK', 'PLZL', 'ROSN', 'SBER', 'SNGS', 'T', 'TATN'],\n",
    "\n",
    "    'batch_size': 32,\n",
    "    'epochs': 100,\n",
    "    'accamulate_grad_batches': 1,\n",
    "    'lr': 3e-4,\n",
    "    'mixed': True,\n",
    "    'patience': 10,\n",
    "    'save_top_k': 5,\n",
    "\n",
    "    'weight_decay': 1e-2,\n",
    "    'max_grad_norm': 1e6,\n",
    "    'batch_scheduler': False,\n",
    "    'scheduler': None,\n",
    "    'scheduler_params': {'eta_min': 1e-5},\n",
    "\n",
    "    'model_name': 'CNN',\n",
    "    'num_workers': 4,\n",
    "    'out_dir': 'D:/Jora/Аспирантура/Stock_forecast_with_investors_sentiment/models/weights/'\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'CNN': CNN,\n",
    "    'CRNN': CRNN,\n",
    "    'CBiRNN': CBiRNN,\n",
    "    'CTransformer': CTransformer\n",
    "}\n",
    "\n",
    "base_model = models[cfg['model_name']]()\n",
    "\n",
    "if cfg['debug']:\n",
    "    kwargs = {'limit_train_batches': 2,\n",
    "              'limit_val_batches': 2, \n",
    "              'num_sanity_val_steps': 0}\n",
    "    cfg['batch_size'] = 2\n",
    "    cfg['epochs'] = 2\n",
    "    cfg['mixed'] = False if cfg['device'] == 'cpu' else True\n",
    "else:\n",
    "    kwargs = {}\n",
    "\n",
    "os.makedirs(cfg['out_dir'] + cfg['model_name'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c03a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PulseSent(L.LightningModule):\n",
    "\n",
    "    def __init__(self, model, lr, epochs, scheduler=None, scheduler_params=None, out_dir=cfg['out_dir']):\n",
    "        super(PulseSent, self).__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.loss = nn.MSELoss()\n",
    "        dev = 'cuda' if cfg['device'] == 'gpu' else 'cpu'\n",
    "        self.metrics = {'f1': F1Score(task='binary').to(dev), 'acc': Accuracy(task='binary').to(dev)}\n",
    "        self.scheduler = scheduler\n",
    "        self.scheduler_params = scheduler_params\n",
    "        self.out_dir = out_dir\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def all_gather_reshape(self, data_lst):\n",
    "        \"\"\"Collects tensors from all GPUs and reshapes them to (NUM_GPUS*N, D, H, W)\"\"\"\n",
    "        data_lst = list(self.all_gather(data_lst))\n",
    "        for i in range(len(data_lst)):\n",
    "            data_lst[i] = data_lst[i].reshape(-1, *data_lst[i].shape[2:])\n",
    "        return data_lst\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        loss = self.loss(out, y)\n",
    "        if self.scheduler:\n",
    "            lr = self.lr_schedulers().get_last_lr()[0]\n",
    "            self.log(f'f{self.fold}-fit/lr', lr, on_step=False,\n",
    "                     on_epoch=True, sync_dist=True)\n",
    "        self.log(f\"train_loss_{self.fold}\", 100*loss.sqrt(), on_step=False,\n",
    "                 on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        val_loss = self.loss(out, y)\n",
    "        if cfg['n_devices'] > 1:\n",
    "            out, y = self.all_gather_reshape((out, y))\n",
    "        for metric in self.metrics:\n",
    "            self.metrics[metric].update(\n",
    "                (out > 0).type(torch.int), (y > 0).type(torch.int))\n",
    "            self.log(f\"val_{metric}_{self.fold}\", self.metrics[metric].compute(\n",
    "            ), on_step=False, on_epoch=True, logger=True, prog_bar=True, sync_dist=True)\n",
    "        self.log(f\"val_loss_{self.fold}\", 100*val_loss.sqrt(), on_step=False,\n",
    "                 on_epoch=True, logger=True, prog_bar=True, sync_dist=True)\n",
    "\n",
    "    def predict_step(self, x):\n",
    "        return self(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(), lr=self.lr, weight_decay=cfg['weight_decay'])\n",
    "        if self.scheduler:\n",
    "            scheduler_dict = {\n",
    "                \"scheduler\": self.scheduler(optimizer, **self.scheduler_params),\n",
    "                'interval': 'step' if cfg['batch_scheduler'] else 'epoch',\n",
    "                'frequency': 1\n",
    "            }\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler_dict}\n",
    "        else:\n",
    "            return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1eb0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df_train: pl.DataFrame, n_lags: int, df_val: pl.DataFrame=None, target_word='diff'):\n",
    "        super().__init__()\n",
    "        df_with_lags = self.create_lags(df_train, n_lags, df_val)\n",
    "\n",
    "        target_cols = [col for col in df_with_lags.columns if target_word in col and 'lag' not in col]\n",
    "        emb_cols = [col for col in df_with_lags.columns if 'column' in col and 'lag' in col]\n",
    "        ts_cols = [col for col in df_with_lags.columns if target_word in col and 'lag' in col]\n",
    "\n",
    "        embs = df_with_lags.select(emb_cols).to_torch(dtype=pl.Float32).view((len(df_with_lags), n_lags, -1))\n",
    "        ts = df_with_lags.select(ts_cols).to_torch(dtype=pl.Float32).view((len(df_with_lags), n_lags, -1))\n",
    "\n",
    "        self.X = torch.cat([embs, ts], dim=-1)\n",
    "        self.y = df_with_lags.select(target_cols).to_torch(dtype=pl.Float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        return self.X[ind], self.y[ind]\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_lags(df_train: pl.DataFrame, n_lags: int, df_val: pl.DataFrame=None):\n",
    "        price_cols = [col for col in df_train.columns if 'diff' in col]\n",
    "        emb_cols = [col for col in df_train.columns if 'column' in col]\n",
    "\n",
    "        if df_val is not None:\n",
    "            val_dates = df_val['date']\n",
    "            df_train = pl.concat([df_train, df_val])\n",
    "        \n",
    "        lag_expressions = []\n",
    "\n",
    "        for lag in range(1, n_lags + 1):\n",
    "            for pc in price_cols:\n",
    "                lag_expressions.append(\n",
    "                    pl.col(pc).shift(lag).alias(f'{pc}_lag_{lag}')\n",
    "                )\n",
    "        \n",
    "        for lag in range(1, n_lags+1):\n",
    "            for ec in emb_cols:\n",
    "                lag_expressions.append(\n",
    "                    pl.col(ec).shift(lag).alias(f'{ec}_lag_{lag}')\n",
    "                )\n",
    "\n",
    "        df_with_lags = df_train.with_columns(lag_expressions)\n",
    "\n",
    "        if df_val is not None:\n",
    "            df_with_lags = df_with_lags.filter(pl.col('date').is_in(val_dates.implode())).sort('date')\n",
    "        \n",
    "        return df_with_lags.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f8d6bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet('../data/final/GAZP.parquet').drop(['weighted_1d', 'open', 'close', 'high', 'low'])\n",
    "\n",
    "df_train = df.filter(pl.col('date') <= datetime.date(2024, 4, 30))\n",
    "df_val = df.filter(pl.col('date') > datetime.date(2024, 4, 30),\n",
    "                   pl.col('date') <= datetime.date(2024, 10, 31))\n",
    "df_test = df.filter(pl.col('date') > datetime.date(2024, 10, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7282aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = SentDataset(df_train, 10)\n",
    "ds_val = SentDataset(df_train, 10, df_val)\n",
    "ds_test = SentDataset(df_val, 10, df_test)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=32, shuffle=True, drop_last=True, pin_memory=True)\n",
    "dl_val = DataLoader(ds_val, batch_size=32, shuffle=False, pin_memory=True)\n",
    "dl_test = DataLoader(ds_test, batch_size=32, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa757807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 10, 389]), torch.Size([32, 5]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in dl_train:\n",
    "    break\n",
    "\n",
    "batch[0].shape, batch[1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
